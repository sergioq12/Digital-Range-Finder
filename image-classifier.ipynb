{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golf Flag Image Classification\n",
    "\n",
    "## Purpose\n",
    "The whole purpose of this notebook is for the creation, training and testing of an image classification model using Tensorflow Keras to classify if a golf flag is within an image.\n",
    "\n",
    "Note: Important to acknowledge that this model was initially coded based on Nicholas Renotte video in youtube: [Image Classification Video](https://www.youtube.com/watch?v=jztwpsIzEGc&t=288s)\n",
    "\n",
    "`-- The code has changed and I have adapted it to my needs.`\n",
    "\n",
    "#### Steps\n",
    "- Install Dependencies and set up\n",
    "- Load Data\n",
    "- Preprocess Data\n",
    "- Create Deep Learning Model\n",
    "- Evaluate Performance\n",
    "- Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow tensorflow-gpu opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consuption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    # telling tensorflow do not use all the GPU memory, only use what you need\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Note if you want to display an image through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the image file path\n",
    "image_path = \"\" # some image file path\n",
    "\n",
    "# 2. Read the image with cv2 (opencv)\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# 3. show it with matplot lib (using pyplot)\n",
    "plt.imshow(img) # if you want to color correct it do: plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from directory using keras\n",
    "# if you want to see the documentation for it run: tf.keras.utils.image_dataset_from_directory?? \n",
    "data = tf.keras.utils.image_dataset_from_directory()\n",
    "\n",
    "# it will by default:\n",
    "# - Set the batch size to 32\n",
    "# - Set the image_size to be (256, 256) \n",
    "# - Shuffle them\n",
    "\n",
    "# the code above produces a generator, then we need to convert it to an iterator\n",
    "data_iterator = data.as_numpy_iterator() # allow to access the elements to iterate\n",
    "\n",
    "# if you want to get a batch of the images do: batch = data_iterator.next()\n",
    "# a batch contains two elements, the image representation (image matrix as numpy arrays) and\n",
    "# the second is the labels (the category of elements in numbers of 0 to more, ex 0 and 1 if there are only two categories)\n",
    "\n",
    "# if we do not know how to flag what label is set to each category you can run the script below which\n",
    "# will show the elements with the labels on top (helpful if you have more than one label)\n",
    "# fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "# for idx, img in enumerate(batch[0][:4]):\n",
    "#     ax[idx].imshow(img.astype(int)) # if the images are black then only use img and not the as type function\n",
    "#     ax[idx].title.set_text(batch[1][idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "For image data we tend to preprocess it. We want to scale the image values to be between 0 and 1 (instead of 0 to 255). This helps the deep learning model generalize faster and produces better results. We are also going to split the data into training, testing and validation data partitions. This will allow us to ensure that we don't overfit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explaining **Overfitting**:\n",
    "Overfitting occurs when a ML model is excessively complex and captures the noise and random fluctuations in the training data, rather than the underlying patterns that we want to learn from. If a model is overfitted it performs exceptionally well on the training data but poorly on new, unseen data.\n",
    "\n",
    "Causes:\n",
    "- Models with too many parameters can easily overfit\n",
    "- Models with insufficient data to learn from, relies in noise and outliers --> outfitting the model\n",
    "- Unclean data leads to overfitting since it will contain errors or random fluctuations that mislead the model\n",
    "\n",
    "How to prevent overfitting:\n",
    "- L1 and L2 Regularization penalize complex models (research on it later)\n",
    "- Dividing data into training and validation sets (cross-validation, which is what we are doing in this model) to assess model performance\n",
    "- Removing irrelevant or dedundant features\n",
    "- Creating new training data by applying transformations to existing data (Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data - as it goes from 0 to 255, to make it from 0 to 1, we need to divide by 255\n",
    "data = data.map(lambda x,y: (x/255, y)) # in this case x being the image value and y the label\n",
    "\n",
    "# to test with the batch (from before in comments) you can do:\n",
    "# scaled = batch[0]/255\n",
    "# scaled.min() # --> should be 0\n",
    "# scaled.max() # --> should be 1\n",
    "\n",
    "# to see that the mapping has happened inside the data pipeline (inside the data object)\n",
    "# run data.as_numpy_iterator().next() and see the values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data - into train, test, and validation\n",
    "# get the actual data parition sizes\n",
    "train_size = int(len(data)*0.7) # ~70%\n",
    "validation_size = int(len(data)*0.2) + 1 # ~20%\n",
    "test_size = int(len(data)*0.1) + 1 # ~10%\n",
    "\n",
    "# split the actual data\n",
    "train_dataset = data.take(train_size)\n",
    "validation_dataset = data.skip(train_size).take(validation_size)\n",
    "test_dataset = data.skip(train_size + validation_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model\n",
    "Build a deep learning model using the Keras Sequential API. \n",
    "\n",
    "Note: I would suggest reading about this API and understanding the type of model that is actually being built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies for the model itself\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "\n",
    "# Sequential (great for one data input and one data output) - flowing from top to bottom\n",
    "# Functional (really powerful for multiple inputs, outputs, connections, more fancy stuff and etc.)\n",
    "\n",
    "# layers:\n",
    "# - Conv2D layer --> Convolutional Layer (Convolutional Neural Network...)\n",
    "# - MaxPooling2D --> Acts as a condensing layer, goes through the images and actually \n",
    "#                    condenses them down (max or min value in a region)\n",
    "# - Dense layer (fully connected layer) --> \n",
    "# - Flatten layer --> allows to go from a convolutional layer that contains multiple channels or kernels and reduces into \n",
    "#                     a format that our dense layer will be able to take\n",
    "# - Dropout --> typically used for regularization\n",
    "\n",
    "# when creating a deep learning model, the architecture of the model is composed of these layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the Sequential model \n",
    "model = Sequential()\n",
    "\n",
    "# chain the layers to the model to create the given architecture (where the magic happens)\n",
    "\n",
    "# first section - convolution input layer\n",
    "# 16 filters that scan over the image, each filter is 3px by 3px in size with a stride of 1\n",
    "# stride of 1 means is moving one pixel at a time\n",
    "# relu activation means that we are taking the output of this convolutional layer \n",
    "# relu function dictamines that each value that was below 0 now will be set to 0 (and preserve the positive values)\n",
    "# input shape is set to be 256px by 256px by 3 channels (only set on first layer)\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation=\"relu\", input_shape=(256,256,3))) \n",
    "model.add(MaxPooling2D()) # take the max values after the relu activation and return that value (default going 2 by 2)\n",
    "\n",
    "# another conv later with 32 filters with size 3px by 3px\n",
    "model.add(Conv2D(32, (3,3), 1, activation=\"relu\"))\n",
    "model.add(MaxPooling2D()) # scan again\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten()) # flattening the channels into a single one\n",
    "\n",
    "# fully connected layers\n",
    "model.add(Dense(256, activation=\"relu\")) # 256 neurons performing a relu activation\n",
    "model.add(Dense(1, activation=\"sigmoid\")) # single neuron, single output after sigmoid activation have values from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we need to compile this architecture\n",
    "model.compile(\"adam\", loss=tf.losses.BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
    "# here \"adam\" is the optimizer (there are a ton of them)\n",
    "# loss in this particular case will be BinaryCrossentropy since we are doing a binary classification problem\n",
    "# tracking accuracy (how good is the model at classifying)\n",
    "\n",
    "# if you want to look at the summary do: model.summary()\n",
    "# the model summary provides the architecture of the model (and see how it transforms the data)\n",
    "# the total number of params, trainable params and non-trainable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# set a directory for the logs of the model after training\n",
    "logdir = \"logs\"\n",
    "\n",
    "# create a callback, really useful to save model at specific checkpoints and do some logging (which is what we are doing)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# fit our model (actually train it)\n",
    "hist = model.fit(train_dataset, epochs=20, validation_data=validation_dataset, callbacks=[tensorboard_callback])\n",
    "\n",
    "# explanation of above script:\n",
    "# takes a training data, then it takes the number of epochs. Each epoch is one run over our entire train data set\n",
    "# pass the validation data, it runs evaluation on the validation data to see how is the model performing in real time\n",
    "# to save the train into a variable, in this case call hist (history), we can get all training information and validation\n",
    "# data\n",
    "\n",
    "# the loss in the training data (you want to see it go down)\n",
    "# the accuracy in the training data (you want to see it go up)\n",
    "\n",
    "# note: the training it will take the most time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance (we can since we saved the variable hist)\n",
    "# hist.history contains loss and accuracy information, let's plot it\n",
    "\n",
    "# plot the loss\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history[\"los\"], color=\"teal\", label=\"loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], color=\"orange\", label=\"val_loss\")\n",
    "fig.suptitle(\"Loss\", fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# if loss is going down and validation loss going up, indication of overfitting\n",
    "# might need to apply some regularization or change some data\n",
    "\n",
    "# if the loss is nos steadily decreasing over time, it might mean that the model itself\n",
    "# is not able to learn accordingly to predict the data. This leads to perhaps changing\n",
    "# the architecture of the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy\n",
    "fig = plt.figure()\n",
    "plt.plot(hist.history[\"accuracy\"], color=\"teal\", label=\"accuracy\")\n",
    "plt.plot(hist.history[\"val_accuracy\"], color=\"orange\", label=\"val_accuracy\")\n",
    "fig.suptitle(\"Accuracy\", fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# it should be increasing over time (ideally using more and more data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Performance\n",
    "Time to test the model. We want to track how the model does and describe its precision, recall and accuracy. These are typical metrics used for classification problems.\n",
    "\n",
    "#### Understanding performance metrics\n",
    "- **Precision**:\n",
    "    - \n",
    "\n",
    "- **Recall**:\n",
    "    - \n",
    "\n",
    "- **Accuracy**:\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imoprt more metric dependencies\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the objects\n",
    "precision_metric = Precision()\n",
    "recall_metric = Recall()\n",
    "accuracy_metric = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually run the testing with the given performance metrics\n",
    "for batch in test_dataset.as_numpy_iterator():\n",
    "    x, y = batch # x being the image content and y the label\n",
    "    \n",
    "    # realize prediction with trained model\n",
    "    yhat = model.predict(x)\n",
    "    precision_metric.update_state(y, yhat)\n",
    "    recall_metric.update_state(y, yhat)\n",
    "    accuracy_metric.update_state(y, yhat)\n",
    "\n",
    "# print the actual results for the performance review (results between 0 and 1)\n",
    "print(f\"Precision Metric: {precision_metric.result().numpy()} - Recall Metric: {recall_metric.result().numpy()} - Binary Accuracy Metric: {accuracy_metric.result().numpy()}\")\n",
    "\n",
    "# research how to make a confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test manully with real images!\n",
    "\n",
    "# get the image file path on your machine\n",
    "image_to_test = \"\"\n",
    "\n",
    "# display image (to see what are we testing with)\n",
    "img_test = cv2.imread(image_to_test)\n",
    "plt.imshow(img_test) # remember to do the color correction if needed\n",
    "plt.show()\n",
    "\n",
    "# prepare the image to be tested\n",
    "resized_image = tf.image.resize(img_test, (256, 256))\n",
    "plt.imshow(resized_image) # remember to do color correction if needed\n",
    "plt.show()\n",
    "\n",
    "# predict (remember that it predicts upon a batch of images not a single one, then encapsulate it into a container (with np.expand_dims))\n",
    "manual_predict_yhat = model.predict(np.expand_dims(resized_image/255, 0)) # at the same time we are scaling it dividing by 255\n",
    "\n",
    "print(yhat) # will give the prediction output (remember to see what is 0 and what is 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to use it again later\n",
    "model.save(os.path.join(\"directory\", \"name_of_model.h5\")) # remember to add the h5, also, put the directory that you want\n",
    "# or just pass a file path that ends in h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to load the model and use it again\n",
    "from tensorflow.keras.models import load_model\n",
    "# new_model = load_model(\"filepath.h5\") # here we just need the file path to that h5 model\n",
    "\n",
    "# run a prediction with:\n",
    "# new_model.predict(np.expand_dims(test_image/255, 0)) # this will do what we showed before"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
